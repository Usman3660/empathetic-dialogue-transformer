{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3238154,"sourceType":"datasetVersion","datasetId":1962861}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tokenizers sacrebleu rouge-score evaluate gradio\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:44:20.712747Z","iopub.execute_input":"2025-10-17T12:44:20.713352Z","iopub.status.idle":"2025-10-17T12:44:34.447807Z","shell.execute_reply.started":"2025-10-17T12:44:20.713325Z","shell.execute_reply":"2025-10-17T12:44:34.446827Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (0.21.2)\nCollecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.38.1)\nCollecting huggingface-hub<1.0,>=0.16.4 (from tokenizers)\n  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2025.9.18)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.1.1)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.9.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.11.0)\nRequirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\nRequirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\nRequirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.1)\nRequirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\nRequirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\nRequirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.0)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\nCollecting pydantic<2.12,>=2.0 (from gradio)\n  Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.3)\nRequirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.5)\nRequirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\nRequirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\nRequirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\nRequirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.15.0)\nRequirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\nCollecting pyarrow>=21.0.0 (from datasets>=2.0.0->evaluate)\n  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nCollecting pydantic-core==2.33.2 (from pydantic<2.12,>=2.0->gradio)\n  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.1.0)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.5.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nDownloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=7d2eb3bc3f7b11ca2f2c5b38c19671470cdc824dcf878be0e784950be9aedde4\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge-score\nInstalling collected packages: pydantic-core, pyarrow, portalocker, pydantic, huggingface-hub, sacrebleu, rouge-score, evaluate\n  Attempting uninstall: pydantic-core\n    Found existing installation: pydantic_core 2.37.2\n    Uninstalling pydantic_core-2.37.2:\n      Successfully uninstalled pydantic_core-2.37.2\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.12.0a1\n    Uninstalling pydantic-2.12.0a1:\n      Successfully uninstalled pydantic-2.12.0a1\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 1.0.0rc2\n    Uninstalling huggingface-hub-1.0.0rc2:\n      Successfully uninstalled huggingface-hub-1.0.0rc2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.6 huggingface-hub-0.35.3 portalocker-3.2.0 pyarrow-21.0.0 pydantic-2.11.10 pydantic-core-2.33.2 rouge-score-0.1.2 sacrebleu-2.5.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom tokenizers import Tokenizer, models, trainers, pre_tokenizers\nfrom sklearn.model_selection import train_test_split\n\n# Load dataset\ndata_path = '/kaggle/input/empathetic-dialogues-facebook-ai/emotion-emotion_69k.csv'\ndf = pd.read_csv(data_path, usecols=['Situation', 'emotion', 'empathetic_dialogues', 'labels'])\ndf = df.rename(columns={'Situation': 'situation', 'emotion': 'emotion', 'labels': 'agent_response'})\ndf = df[['situation', 'emotion', 'agent_response']]\ndf.dropna(subset=['situation', 'emotion', 'agent_response'], inplace=True)\ndf.reset_index(drop=True, inplace=True)\n\n# Normalize text\ndef normalize_text(text):\n    if not isinstance(text, str):\n        return \"\"\n    text = text.lower().strip()\n    text = re.sub(r'\\s+', ' ', text)  # Clean whitespace\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n    return text\n\ndf['situation'] = df['situation'].apply(normalize_text)\ndf['agent_response'] = df['agent_response'].apply(normalize_text)\ndf['emotion'] = df['emotion'].apply(lambda x: str(x).lower().strip())\n\n# Split dataset (80/10/10)\ntrain_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\nval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n\n# Build BPE Tokenizer\ndef build_tokenizer(train_df):\n    tokenizer = Tokenizer(models.BPE())\n    tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n    special_tokens = [\"<pad>\", \"<bos>\", \"<eos>\", \"<unk>\", \"<sep>\"] + [f\"<emotion_{emo}>\" for emo in train_df['emotion'].unique()]\n    trainer = trainers.BpeTrainer(vocab_size=30000, special_tokens=special_tokens)\n    texts = (train_df['situation'] + ' ' + train_df['agent_response']).tolist()\n    tokenizer.train_from_iterator(texts, trainer=trainer)\n    tokenizer.save(\"/kaggle/working/tokenizer.json\")\n    return tokenizer\n\ntokenizer = build_tokenizer(train_df)\n\n# Encode Input & Target\ndef prepare_input(row):\n    input_text = f\"Emotion: {row['emotion']} | Situation: {row['situation']} Agent:\"\n    return tokenizer.encode(f\"<bos> {input_text}\").ids\n\ndef prepare_target(row):\n    target_text = row['agent_response']\n    return tokenizer.encode(f\"{target_text} <eos>\").ids\n\nfor split_df in [train_df, val_df, test_df]:\n    split_df['input_ids'] = split_df.apply(prepare_input, axis=1)\n    split_df['target_ids'] = split_df.apply(prepare_target, axis=1)\n\n# Save preprocessed datasets\ntrain_df.to_csv(\"/kaggle/working/train_preprocessed.csv\", index=False)\nval_df.to_csv(\"/kaggle/working/val_preprocessed.csv\", index=False)\ntest_df.to_csv(\"/kaggle/working/test_preprocessed.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:46:40.541307Z","iopub.execute_input":"2025-10-17T12:46:40.542006Z","iopub.status.idle":"2025-10-17T12:46:50.120902Z","shell.execute_reply.started":"2025-10-17T12:46:40.541974Z","shell.execute_reply":"2025-10-17T12:46:50.120077Z"}},"outputs":[{"name":"stdout","text":"\n\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass EmpatheticDataset(Dataset):\n    def __init__(self, df, max_len=128):\n        self.inputs = df['input_ids'].tolist()\n        self.targets = df['target_ids'].tolist()\n        self.max_len = max_len\n        self.pad_id = tokenizer.token_to_id(\"<pad>\")\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        inp = self.inputs[idx][:self.max_len] + [self.pad_id] * max(0, self.max_len - len(self.inputs[idx]))\n        tgt = self.targets[idx][:self.max_len] + [self.pad_id] * max(0, self.max_len - len(self.targets[idx]))\n        return torch.tensor(inp, dtype=torch.long), torch.tensor(tgt, dtype=torch.long)\n\ntrain_dataset = EmpatheticDataset(train_df)\nval_dataset = EmpatheticDataset(val_df)\ntest_dataset = EmpatheticDataset(test_df)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32)\ntest_loader = DataLoader(test_dataset, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:50:36.122459Z","iopub.execute_input":"2025-10-17T12:50:36.123104Z","iopub.status.idle":"2025-10-17T12:50:36.132615Z","shell.execute_reply.started":"2025-10-17T12:50:36.123078Z","shell.execute_reply":"2025-10-17T12:50:36.131979Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport sacrebleu\nimport math\n\n# ----------------------------\n# Positional Encoding\n# ----------------------------\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        return x + self.pe[:, :x.size(1)]\n\n# ----------------------------\n# Multi-Head Attention\n# ----------------------------\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        assert d_model % num_heads == 0\n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.d_k = d_model // num_heads\n        self.q_linear = nn.Linear(d_model, d_model)\n        self.k_linear = nn.Linear(d_model, d_model)\n        self.v_linear = nn.Linear(d_model, d_model)\n        self.out_linear = nn.Linear(d_model, d_model)\n\n    def forward(self, q, k, v, mask=None):\n        bs = q.size(0)\n        q = self.q_linear(q).view(bs, -1, self.num_heads, self.d_k).transpose(1, 2)\n        k = self.k_linear(k).view(bs, -1, self.num_heads, self.d_k).transpose(1, 2)\n        v = self.v_linear(v).view(bs, -1, self.num_heads, self.d_k).transpose(1, 2)\n        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)\n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, -1e9)\n        attn = torch.softmax(scores, dim=-1)\n        out = torch.matmul(attn, v).transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n        return self.out_linear(out)\n\n# ----------------------------\n# Feed Forward\n# ----------------------------\nclass FeedForward(nn.Module):\n    def __init__(self, d_model, d_ff=2048):\n        super().__init__()\n        self.linear1 = nn.Linear(d_model, d_ff)\n        self.linear2 = nn.Linear(d_ff, d_model)\n\n    def forward(self, x):\n        return self.linear2(torch.relu(self.linear1(x)))\n\n# ----------------------------\n# Encoder Layer\n# ----------------------------\nclass EncoderLayer(nn.Module):\n    def __init__(self, d_model, num_heads, dropout=0.1):\n        super().__init__()\n        self.mha = MultiHeadAttention(d_model, num_heads)\n        self.ff = FeedForward(d_model)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, mask):\n        attn = self.mha(x, x, x, mask)\n        x = self.norm1(x + self.dropout(attn))\n        ff = self.ff(x)\n        return self.norm2(x + self.dropout(ff))\n\n# ----------------------------\n# Decoder Layer\n# ----------------------------\nclass DecoderLayer(nn.Module):\n    def __init__(self, d_model, num_heads, dropout=0.1):\n        super().__init__()\n        self.self_mha = MultiHeadAttention(d_model, num_heads)\n        self.cross_mha = MultiHeadAttention(d_model, num_heads)\n        self.ff = FeedForward(d_model)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, enc_out, src_mask, tgt_mask):\n        self_attn = self.self_mha(x, x, x, tgt_mask)\n        x = self.norm1(x + self.dropout(self_attn))\n        cross_attn = self.cross_mha(x, enc_out, enc_out, src_mask)\n        x = self.norm2(x + self.dropout(cross_attn))\n        ff = self.ff(x)\n        return self.norm3(x + self.dropout(ff))\n\n# ----------------------------\n# Full Transformer Model\n# ----------------------------\nclass Transformer(nn.Module):\n    def __init__(self, vocab_size, d_model=256, num_heads=2, num_enc_layers=2, num_dec_layers=2, dropout=0.1):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, d_model)\n        self.pos_enc = PositionalEncoding(d_model)\n        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, dropout) for _ in range(num_enc_layers)])\n        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, dropout) for _ in range(num_dec_layers)])\n        self.linear = nn.Linear(d_model, vocab_size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n        src_emb = self.dropout(self.pos_enc(self.embedding(src)))\n        tgt_emb = self.dropout(self.pos_enc(self.embedding(tgt)))\n        enc_out = src_emb\n        for layer in self.encoder_layers:\n            enc_out = layer(enc_out, src_mask)\n        dec_out = tgt_emb\n        for layer in self.decoder_layers:\n            dec_out = layer(dec_out, enc_out, src_mask, tgt_mask)\n        return self.linear(dec_out)\n\n# ----------------------------\n# Helper Functions\n# ----------------------------\ndef generate_square_subsequent_mask(sz):\n    mask = torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n    return mask == 0\n\ndef create_padding_mask(seq, pad_id):\n    return (seq != pad_id).unsqueeze(1).unsqueeze(2)\n\n# ----------------------------\n# Training Setup\n# ----------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Placeholder for tokenizer - ensure this is defined elsewhere (e.g., preprocess.py)\n# Example: tokenizer = some_loaded_tokenizer with methods get_vocab_size(), token_to_id(), decode()\ntry:\n    model = Transformer(vocab_size=tokenizer.get_vocab_size()).to(device)\nexcept NameError:\n    raise NameError(\"Tokenizer not defined. Please run preprocess.py or define tokenizer with get_vocab_size(), token_to_id(), and decode() methods.\")\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98))\ncriterion = nn.CrossEntropyLoss(ignore_index=tokenizer.token_to_id(\"<pad>\"))\n\n# Placeholder for data loaders - ensure these are defined elsewhere (e.g., preprocess.py)\n# Example: train_loader, val_loader = some_data_loading_function()\nif 'train_loader' not in globals() or 'val_loader' not in globals():\n    raise NameError(\"train_loader and/or val_loader not defined. Please run preprocess.py or define them as DataLoader objects.\")\n\n# ----------------------------\n# Training Loop\n# ----------------------------\ndef train_epoch(model, loader, optimizer, criterion):\n    model.train()\n    total_loss = 0\n    for src, tgt in loader:\n        src, tgt = src.to(device), tgt.to(device)\n        optimizer.zero_grad()\n        tgt_input = tgt[:, :-1]\n        tgt_out = tgt[:, 1:]\n        src_mask = create_padding_mask(src, tokenizer.token_to_id(\"<pad>\")).to(device)\n        tgt_mask = generate_square_subsequent_mask(tgt_input.size(1)).to(device) & create_padding_mask(tgt_input, tokenizer.token_to_id(\"<pad>\")).to(device)\n        preds = model(src, tgt_input, src_mask, tgt_mask)\n        loss = criterion(preds.view(-1, preds.size(-1)), tgt_out.reshape(-1))\n        loss.backward()\n        # Add gradient clipping for stability\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(loader)\n\n# ----------------------------\n# Greedy Decoding\n# ----------------------------\ndef greedy_decode(model, src, max_len=50):\n    model.eval()\n    src = src.to(device)\n    if len(src.shape) == 1:\n        src = src.unsqueeze(0)\n    batch_size = src.size(0)\n    src_mask = create_padding_mask(src, tokenizer.token_to_id(\"<pad>\")).to(device)\n    enc_out = model.dropout(model.pos_enc(model.embedding(src)))\n    for layer in model.encoder_layers:\n        enc_out = layer(enc_out, src_mask)\n    ys = torch.tensor([[tokenizer.token_to_id(\"<bos>\")]] * batch_size, device=device)\n    for _ in range(max_len):\n        tgt_mask = generate_square_subsequent_mask(ys.size(1)).to(device)\n        dec_out = model.dropout(model.pos_enc(model.embedding(ys)))\n        for layer in model.decoder_layers:\n            dec_out = layer(dec_out, enc_out, src_mask, tgt_mask)\n        pred = model.linear(dec_out[:, -1, :])\n        next_token = pred.argmax(1)\n        ys = torch.cat((ys, next_token.unsqueeze(1)), dim=1)\n        if torch.all(next_token == tokenizer.token_to_id(\"<eos>\")):\n            break\n    return ys[:, 1:].cpu().tolist()\n\n# ----------------------------\n# Compute BLEU\n# ----------------------------\ndef compute_bleu(model, loader):\n    model.eval()\n    refs, hyps = [], []\n    with torch.no_grad():\n        for src, tgt in loader:\n            src = src.to(device)\n            preds = greedy_decode(model, src)\n            hyps.extend([tokenizer.decode(p).strip() for p in preds])\n            refs.extend([tokenizer.decode(t[1:].tolist()).strip() for t in tgt])\n    return sacrebleu.corpus_bleu(hyps, [[r] for r in refs]).score\n\n# ----------------------------\n# Full Training Loop\n# ----------------------------\nbest_bleu = 0\nfor epoch in range(10):\n    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n    val_bleu = compute_bleu(model, val_loader)\n    if val_bleu > best_bleu:\n        torch.save(model.state_dict(), '/kaggle/working/best_model.pt')\n        best_bleu = val_bleu\n    print(f\"Epoch {epoch+1}: Loss = {train_loss:.4f}, Val BLEU = {val_bleu:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:50:41.729554Z","iopub.execute_input":"2025-10-17T12:50:41.729844Z","iopub.status.idle":"2025-10-17T13:26:57.406322Z","shell.execute_reply.started":"2025-10-17T12:50:41.729822Z","shell.execute_reply":"2025-10-17T13:26:57.405466Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: Loss = 5.5120, Val BLEU = 64.68\nEpoch 2: Loss = 4.8166, Val BLEU = 70.71\nEpoch 3: Loss = 4.6245, Val BLEU = 75.98\nEpoch 4: Loss = 4.5010, Val BLEU = 100.00\nEpoch 5: Loss = 4.4085, Val BLEU = 100.00\nEpoch 6: Loss = 4.3298, Val BLEU = 100.00\nEpoch 7: Loss = 4.2636, Val BLEU = 100.00\nEpoch 8: Loss = 4.2030, Val BLEU = 100.00\nEpoch 9: Loss = 4.1476, Val BLEU = 79.53\nEpoch 10: Loss = 4.0968, Val BLEU = 100.00\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install tokenizers sacrebleu rouge-score evaluate gradio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T13:28:44.847922Z","iopub.execute_input":"2025-10-17T13:28:44.848195Z","iopub.status.idle":"2025-10-17T13:28:48.449455Z","shell.execute_reply.started":"2025-10-17T13:28:44.848177Z","shell.execute_reply":"2025-10-17T13:28:48.448696Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (0.21.2)\nRequirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\nRequirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\nRequirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.6)\nRequirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.38.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers) (0.35.3)\nRequirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.2.0)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2025.9.18)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.1.1)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.9.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.11.0)\nRequirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\nRequirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\nRequirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.1)\nRequirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\nRequirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\nRequirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.0)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\nRequirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.10)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.3)\nRequirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.5)\nRequirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\nRequirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\nRequirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\nRequirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.15.0)\nRequirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (21.0.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.1.0)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.5.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118\n!pip install tokenizers sacrebleu rouge-score evaluate gradio transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T13:28:58.939634Z","iopub.execute_input":"2025-10-17T13:28:58.939945Z","iopub.status.idle":"2025-10-17T13:30:56.436373Z","shell.execute_reply.started":"2025-10-17T13:28:58.939917Z","shell.execute_reply":"2025-10-17T13:30:56.435595Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu118\nCollecting torch==2.1.2\n  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.2%2Bcu118-cp311-cp311-linux_x86_64.whl (2325.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m402.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision==0.16.2\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchaudio==2.1.2\n  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.2%2Bcu118-cp311-cp311-linux_x86_64.whl (3.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.19.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (4.15.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (2025.9.0)\nCollecting triton==2.1.0 (from torch==2.1.2)\n  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.2) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.2) (2.32.5)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.2) (11.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.2) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.16.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.16.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.16.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.16.2) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.16.2) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.16.2) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (2025.8.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.2) (1.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.16.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.16.2) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.16.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision==0.16.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision==0.16.2) (2024.2.0)\nInstalling collected packages: triton, torch, torchaudio, torchvision\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.6.0+cu124\n    Uninstalling torchaudio-2.6.0+cu124:\n      Successfully uninstalled torchaudio-2.6.0+cu124\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\nSuccessfully installed torch-2.1.2+cu118 torchaudio-2.1.2+cu118 torchvision-0.16.2+cu118 triton-2.1.0\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (0.21.2)\nRequirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\nRequirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\nRequirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.6)\nRequirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.38.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers) (0.35.3)\nRequirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.2.0)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2025.9.18)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.1.1)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.9.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.11.0)\nRequirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\nRequirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\nRequirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.1)\nRequirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\nRequirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\nRequirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.0)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\nRequirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.10)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.3)\nRequirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.5)\nRequirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\nRequirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\nRequirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\nRequirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.15.0)\nRequirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.19.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (21.0.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.1.0)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.5.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport math\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom tokenizers import Tokenizer\nfrom sklearn.model_selection import train_test_split\nimport sacrebleu\nfrom rouge_score import rouge_scorer\nimport numpy as np\n\n# NOTE: This script assumes the first two code blocks from your original prompt\n# (data preprocessing and model architecture) have been run. It defines the\n# evaluation components.\n\n# ----------------------------\n# Helper Functions (from original code)\n# ----------------------------\ndef generate_square_subsequent_mask(sz):\n    mask = torch.triu(torch.ones(sz, sz, device=device) * float('-inf'), diagonal=1)\n    return mask == 0\n\ndef create_padding_mask(seq, pad_id):\n    return (seq != pad_id).unsqueeze(1).unsqueeze(2)\n\n# --- Ensure Tokenizer, Model, and DataLoaders are loaded ---\n# In a real script, you would load these from files. For this example,\n# we'll assume they are available from the previous steps.\n# For reproducibility, let's redefine them briefly.\n\n# Dummy definitions for demonstration if not run in sequence\ntry:\n    tokenizer = Tokenizer.from_file(\"/kaggle/working/tokenizer.json\")\n    pad_id = tokenizer.token_to_id(\"<pad>\")\n    bos_id = tokenizer.token_to_id(\"<bos>\")\n    eos_id = tokenizer.token_to_id(\"<eos>\")\nexcept (NameError, FileNotFoundError):\n    print(\"Tokenizer not found. Please run the preprocessing script first.\")\n    exit()\n\n# Assume 'Transformer' class definition exists from the original code\n# Assume 'test_loader' is defined from the original code\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = Transformer(vocab_size=tokenizer.get_vocab_size()).to(device)\ntry:\n    model.load_state_dict(torch.load('/kaggle/working/best_model.pt', map_location=device))\n    print(\"Model loaded successfully.\")\nexcept FileNotFoundError:\n    print(\"Model weights not found. Evaluation will be on an untrained model.\")\n\n# -------------------------------------\n# 5. EVALUATION IMPLEMENTATION\n# -------------------------------------\n\n## Automatic Metrics Calculation\n\ndef greedy_decode(model, src, max_len=50):\n    \"\"\"Generates text for a given source tensor.\"\"\"\n    model.eval()\n    src = src.to(device)\n    if src.dim() == 1:\n        src = src.unsqueeze(0)\n    batch_size = src.size(0)\n\n    # Re-using encoder logic from original training code for consistency\n    src_mask = create_padding_mask(src, pad_id).to(device)\n    with torch.no_grad():\n        enc_out = model.dropout(model.pos_enc(model.embedding(src)))\n        for layer in model.encoder_layers:\n            enc_out = layer(enc_out, src_mask)\n\n    ys = torch.full((batch_size, 1), bos_id, dtype=torch.long, device=device)\n\n    for _ in range(max_len - 1):\n        with torch.no_grad():\n            tgt_mask = generate_square_subsequent_mask(ys.size(1)).to(device)\n            dec_out = model.dropout(model.pos_enc(model.embedding(ys)))\n            for layer in model.decoder_layers:\n                dec_out = layer(dec_out, enc_out, src_mask, tgt_mask)\n            pred = model.linear(dec_out[:, -1, :])\n            next_token = pred.argmax(dim=-1)\n\n        # Stop if all sequences in batch have generated <eos>\n        if torch.all(next_token == eos_id).item():\n            break\n            \n        ys = torch.cat([ys, next_token.unsqueeze(1)], dim=1)\n\n    return ys.cpu().tolist()\n\n\ndef calculate_metrics(model, loader):\n    \"\"\"Calculates BLEU, ROUGE-L, chrF, and Perplexity.\"\"\"\n    model.eval()\n    \n    # For automatic metrics\n    hypotheses = [] # Model predictions\n    references = [] # Ground truth\n    \n    # For perplexity\n    total_loss = 0\n    total_tokens = 0\n    \n    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n    rouge_l_f1 = []\n\n    criterion = nn.CrossEntropyLoss(ignore_index=pad_id, reduction='sum')\n\n    with torch.no_grad():\n        for src, tgt in loader:\n            src, tgt = src.to(device), tgt.to(device)\n            \n            # --- Perplexity Calculation ---\n            tgt_input = tgt[:, :-1]\n            tgt_out = tgt[:, 1:]\n            src_mask = create_padding_mask(src, pad_id)\n            tgt_mask = generate_square_subsequent_mask(tgt_input.size(1)) & create_padding_mask(tgt_input, pad_id)\n            \n            preds = model(src, tgt_input, src_mask, tgt_mask)\n            loss = criterion(preds.view(-1, preds.size(-1)), tgt_out.reshape(-1))\n            \n            # Count non-padded tokens for accurate PPL\n            non_pad_tokens = (tgt_out != pad_id).sum().item()\n            total_loss += loss.item()\n            total_tokens += non_pad_tokens\n\n            # --- BLEU, ROUGE, chrF Calculation ---\n            generated_ids = greedy_decode(model, src)\n            \n            # Decode for metric calculation\n            batch_hyps = [tokenizer.decode(ids).strip() for ids in generated_ids]\n            batch_refs = [tokenizer.decode(ids).strip() for ids in tgt.cpu().tolist()]\n\n            hypotheses.extend(batch_hyps)\n            references.extend(batch_refs)\n\n    # --- Final Metric Scores ---\n    bleu = sacrebleu.corpus_bleu(hypotheses, [[r] for r in references])\n    chrf = sacrebleu.corpus_chrf(hypotheses, [[r] for r in references])\n    \n    # Calculate ROUGE-L per sentence and average\n    for hyp, ref in zip(hypotheses, references):\n        scores = scorer.score(ref, hyp)\n        rouge_l_f1.append(scores['rougeL'].fmeasure)\n    \n    avg_rouge_l = np.mean(rouge_l_f1) * 100\n    \n    # Calculate perplexity\n    perplexity = math.exp(total_loss / total_tokens) if total_tokens > 0 else float('inf')\n\n    return {\n        \"BLEU\": bleu.score,\n        \"ROUGE-L\": avg_rouge_l,\n        \"chrF\": chrf.score,\n        \"Perplexity\": perplexity\n    }, hypotheses, references\n\n## Human Evaluation Framework\n\ndef human_evaluation_interface(situation, ground_truth, model_output):\n    \"\"\"Simulates a human evaluation task for a single example.\"\"\"\n    print(\"\\n--- Human Evaluation Example ---\")\n    print(f\"Situation: {situation}\")\n    print(f\"Ground Truth Response: {ground_truth}\")\n    print(f\"Model Generated Response: {model_output}\")\n    print(\"-\" * 20)\n    \n    try:\n        fluency = int(input(\"Rate Fluency (1-5): \"))\n        relevance = int(input(\"Rate Relevance (1-5): \"))\n        adequacy = int(input(\"Rate Adequacy/Empathy (1-5): \"))\n        return {\"fluency\": fluency, \"relevance\": relevance, \"adequacy\": adequacy}\n    except (ValueError, EOFError):\n        print(\"Invalid input. Skipping.\")\n        return None\n\n## Qualitative Examples\n\ndef show_qualitative_examples(test_df, hyps, refs, num_examples=5):\n    \"\"\"Prints a comparison of model output and ground truth.\"\"\"\n    print(\"\\n--- Qualitative Examples ---\")\n    \n    # We need the original text, so we'll use the test dataframe\n    samples = test_df.head(num_examples)\n    \n    for i, (idx, row) in enumerate(samples.iterrows()):\n        print(f\"\\n--- Example {i+1} ---\")\n        print(f\"Emotion: {row['emotion']}\")\n        print(f\"Situation: {row['situation']}\")\n        print(f\"✅ Ground Truth: {refs[i]}\")\n        print(f\"🤖 Model Output: {hyps[i]}\")\n        print(\"-\" * 20)\n        \n# --- Main Evaluation Execution ---\nif __name__ == \"__main__\":\n    # Load the test dataframe to get original text for examples\n    try:\n        test_df = pd.read_csv(\"/kaggle/working/test_preprocessed.csv\")\n    except FileNotFoundError:\n        print(\"Preprocessed test CSV not found. Cannot show qualitative examples.\")\n        test_df = None\n\n    print(\"Running evaluation on the test set...\")\n    metrics, hyps, refs = calculate_metrics(model, test_loader)\n    \n    print(\"\\n--- Automatic Metrics ---\")\n    print(f\"📊 Perplexity: {metrics['Perplexity']:.2f}\")\n    print(f\"📊 BLEU Score: {metrics['BLEU']:.2f}\")\n    print(f\"📊 ROUGE-L (F1): {metrics['ROUGE-L']:.2f}\")\n    print(f\"📊 chrF Score: {metrics['chrF']:.2f}\")\n    \n    if test_df is not None:\n        show_qualitative_examples(test_df, hyps, refs)\n    \n        # Run a few examples through the human evaluation interface\n        print(\"\\nStarting interactive human evaluation for the first 3 examples...\")\n        all_human_scores = []\n        for i in range(3):\n            scores = human_evaluation_interface(\n                situation=test_df.iloc[i]['situation'],\n                ground_truth=refs[i],\n                model_output=hyps[i]\n            )\n            if scores:\n                all_human_scores.append(scores)\n        \n        if all_human_scores:\n            avg_fluency = np.mean([s['fluency'] for s in all_human_scores])\n            avg_relevance = np.mean([s['relevance'] for s in all_human_scores])\n            avg_adequacy = np.mean([s['adequacy'] for s in all_human_scores])\n            print(\"\\n--- Average Human Scores (from your ratings) ---\")\n            print(f\"⭐ Fluency: {avg_fluency:.2f}\")\n            print(f\"⭐ Relevance: {avg_relevance:.2f}\")\n            print(f\"⭐ Adequacy/Empathy: {avg_adequacy:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T13:31:32.888400Z","iopub.execute_input":"2025-10-17T13:31:32.888744Z","iopub.status.idle":"2025-10-17T13:35:00.585516Z","shell.execute_reply.started":"2025-10-17T13:31:32.888709Z","shell.execute_reply":"2025-10-17T13:35:00.584911Z"}},"outputs":[{"name":"stdout","text":"Model loaded successfully.\nRunning evaluation on the test set...\n\n--- Automatic Metrics ---\n📊 Perplexity: 99.25\n📊 BLEU Score: 88.01\n📊 ROUGE-L (F1): 8.98\n📊 chrF Score: 73.12\n\n--- Qualitative Examples ---\n\n--- Example 1 ---\nEmotion: trusting\nSituation: i sent a parcel to my cousin recently and it never arrived it cost me 50\n✅ Ground Truth: thank you for your kind words and wishes\n🤖 Model Output: you must be very proud of your family\n--------------------\n\n--- Example 2 ---\nEmotion: terrified\nSituation: someone has knocked on my door in the middle of the night the past two nights it is kind startling and scary\n✅ Ground Truth: did they knock and leave\n🤖 Model Output: you have to do that\n--------------------\n\n--- Example 3 ---\nEmotion: jealous\nSituation: im jealous with people that have gyms in their homes i would work out every day if i had one\n✅ Ground Truth: yes youtube will def have some awesome ideas i could stand to get rid of this gut also hahahah\n🤖 Model Output: you can do that\n--------------------\n\n--- Example 4 ---\nEmotion: impressed\nSituation: i went to an auction last week and saw someone spend one million dollars\n✅ Ground Truth: yea some other guy but no one else\n🤖 Model Output: you must be proud of him\n--------------------\n\n--- Example 5 ---\nEmotion: sentimental\nSituation: i found a ring i thought i had lost recently when i was cleaning out my closet it had belonged to my grandfather and it was very special to me\n✅ Ground Truth: it mustve been a great guy\n🤖 Model Output: you must have been so much fun\n--------------------\n\nStarting interactive human evaluation for the first 3 examples...\n\n--- Human Evaluation Example ---\nSituation: i sent a parcel to my cousin recently and it never arrived it cost me 50\nGround Truth Response: thank you for your kind words and wishes\nModel Generated Response: you must be very proud of your family\n--------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Rate Fluency (1-5):  1\nRate Relevance (1-5):  5\nRate Adequacy/Empathy (1-5):  3\n"},{"name":"stdout","text":"\n--- Human Evaluation Example ---\nSituation: someone has knocked on my door in the middle of the night the past two nights it is kind startling and scary\nGround Truth Response: did they knock and leave\nModel Generated Response: you have to do that\n--------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Rate Fluency (1-5):  2\nRate Relevance (1-5):  4\nRate Adequacy/Empathy (1-5):  3\n"},{"name":"stdout","text":"\n--- Human Evaluation Example ---\nSituation: im jealous with people that have gyms in their homes i would work out every day if i had one\nGround Truth Response: yes youtube will def have some awesome ideas i could stand to get rid of this gut also hahahah\nModel Generated Response: you can do that\n--------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Rate Fluency (1-5):  5\nRate Relevance (1-5):  4\nRate Adequacy/Empathy (1-5):  3\n"},{"name":"stdout","text":"\n--- Average Human Scores (from your ratings) ---\n⭐ Fluency: 2.67\n⭐ Relevance: 4.33\n⭐ Adequacy/Empathy: 3.00\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# This creates a link to the file in the output of this cell\ndisplay(FileLink('best_model.pt'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T13:53:38.682841Z","iopub.execute_input":"2025-10-17T13:53:38.683177Z","iopub.status.idle":"2025-10-17T13:53:38.689707Z","shell.execute_reply.started":"2025-10-17T13:53:38.683155Z","shell.execute_reply":"2025-10-17T13:53:38.689165Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"/kaggle/working/best_model.pt","text/html":"<a href='best_model.pt' target='_blank'>best_model.pt</a><br>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"pip install streamlit torch tokenizers sacrebleu pandas numpy matplotlib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T11:03:25.290173Z","iopub.execute_input":"2025-10-17T11:03:25.290468Z","iopub.status.idle":"2025-10-17T11:03:34.612510Z","shell.execute_reply.started":"2025-10-17T11:03:25.290449Z","shell.execute_reply":"2025-10-17T11:03:34.611687Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting streamlit\n  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.1.2+cu118)\nRequirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (0.21.2)\nRequirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\nRequirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\nRequirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.3.0)\nRequirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\nRequirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\nRequirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (21.0.0)\nRequirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.5)\nRequirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\nRequirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.15.0)\nRequirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.5.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.19.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.9.0)\nRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (2.1.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers) (0.35.3)\nRequirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.2.0)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2025.9.18)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\nRequirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (1.48.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (1.1.10)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.26.0)\nDownloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m0m\n\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pydeck, streamlit\nSuccessfully installed pydeck-0.9.1 streamlit-1.50.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import streamlit as st\nimport torch\nimport torch.nn as nn\nimport math\nimport re\nfrom tokenizers import Tokenizer\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n# --- 1. MODEL ARCHITECTURE DEFINITION ---\n# This section contains the PyTorch model classes, copied from the training script.\n# It's necessary to define the architecture before loading the saved model weights.\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        return x + self.pe[:, :x.size(1)]\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        assert d_model % num_heads == 0\n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.d_k = d_model // num_heads\n        self.q_linear = nn.Linear(d_model, d_model)\n        self.k_linear = nn.Linear(d_model, d_model)\n        self.v_linear = nn.Linear(d_model, d_model)\n        self.out_linear = nn.Linear(d_model, d_model)\n        self.attention_weights = None\n\n    def forward(self, q, k, v, mask=None):\n        bs = q.size(0)\n        q = self.q_linear(q).view(bs, -1, self.num_heads, self.d_k).transpose(1, 2)\n        k = self.k_linear(k).view(bs, -1, self.num_heads, self.d_k).transpose(1, 2)\n        v = self.v_linear(v).view(bs, -1, self.num_heads, self.d_k).transpose(1, 2)\n        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)\n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, -1e9)\n        attn = torch.softmax(scores, dim=-1)\n        self.attention_weights = attn # Store attention weights\n        out = torch.matmul(attn, v).transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n        return self.out_linear(out)\n\nclass FeedForward(nn.Module):\n    def __init__(self, d_model, d_ff=2048):\n        super().__init__()\n        self.linear1 = nn.Linear(d_model, d_ff)\n        self.linear2 = nn.Linear(d_ff, d_model)\n\n    def forward(self, x):\n        return self.linear2(torch.relu(self.linear1(x)))\n\nclass EncoderLayer(nn.Module):\n    def __init__(self, d_model, num_heads, dropout=0.1):\n        super().__init__()\n        self.mha = MultiHeadAttention(d_model, num_heads)\n        self.ff = FeedForward(d_model)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, mask):\n        attn = self.mha(x, x, x, mask)\n        x = self.norm1(x + self.dropout(attn))\n        ff = self.ff(x)\n        return self.norm2(x + self.dropout(ff))\n\nclass DecoderLayer(nn.Module):\n    def __init__(self, d_model, num_heads, dropout=0.1):\n        super().__init__()\n        self.self_mha = MultiHeadAttention(d_model, num_heads)\n        self.cross_mha = MultiHeadAttention(d_model, num_heads)\n        self.ff = FeedForward(d_model)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, enc_out, src_mask, tgt_mask):\n        self_attn = self.self_mha(x, x, x, tgt_mask)\n        x = self.norm1(x + self.dropout(self_attn))\n        cross_attn = self.cross_mha(x, enc_out, enc_out, src_mask)\n        x = self.norm2(x + self.dropout(cross_attn))\n        ff = self.ff(x)\n        return self.norm3(x + self.dropout(ff))\n\nclass Transformer(nn.Module):\n    def __init__(self, vocab_size, d_model=256, num_heads=2, num_enc_layers=2, num_dec_layers=2, dropout=0.1):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, d_model)\n        self.pos_enc = PositionalEncoding(d_model)\n        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, dropout) for _ in range(num_enc_layers)])\n        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, dropout) for _ in range(num_dec_layers)])\n        self.linear = nn.Linear(d_model, vocab_size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n        src_emb = self.dropout(self.pos_enc(self.embedding(src)))\n        tgt_emb = self.dropout(self.pos_enc(self.embedding(tgt)))\n        enc_out = src_emb\n        for layer in self.encoder_layers:\n            enc_out = layer(enc_out, src_mask)\n        dec_out = tgt_emb\n        for i, layer in enumerate(self.decoder_layers):\n            dec_out = layer(dec_out, enc_out, src_mask, tgt_mask)\n        return self.linear(dec_out)\n\n# --- 2. SETUP AND UTILITY FUNCTIONS ---\n\n# Use @st.cache_resource to load model and tokenizer only once\n@st.cache_resource\ndef load_model_and_tokenizer():\n    \"\"\"Loads the trained Transformer model and tokenizer.\"\"\"\n    try:\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        tokenizer = Tokenizer.from_file(\"tokenizer.json\")\n        \n        # Instantiate model with parameters from training\n        vocab_size = tokenizer.get_vocab_size()\n        model = Transformer(vocab_size=vocab_size, d_model=256, num_heads=2, num_enc_layers=2, num_dec_layers=2)\n        \n        # Load the saved state dictionary\n        model.load_state_dict(torch.load('best_model.pt', map_location=device))\n        model.to(device)\n        model.eval()\n        return model, tokenizer, device\n    except FileNotFoundError:\n        st.error(\"Model or tokenizer file not found. Please ensure 'best_model.pt' and 'tokenizer.json' are in the same directory.\")\n        return None, None, None\n\ndef normalize_text(text):\n    \"\"\"Cleans and standardizes text.\"\"\"\n    if not isinstance(text, str):\n        return \"\"\n    text = text.lower().strip()\n    text = re.sub(r'\\s+', ' ', text)\n    text = re.sub(r'[^\\w\\s]', '', text)\n    return text\n\ndef create_masks(src, tgt, pad_id, device):\n    \"\"\"Creates masks for the Transformer model.\"\"\"\n    src_mask = (src != pad_id).unsqueeze(1).unsqueeze(2).to(device)\n    tgt_len = tgt.size(1)\n    tgt_mask = (torch.triu(torch.ones(tgt_len, tgt_len), diagonal=1) == 0).to(device)\n    tgt_pad_mask = (tgt != pad_id).unsqueeze(1).unsqueeze(2).to(device)\n    tgt_mask = tgt_mask & tgt_pad_mask\n    return src_mask, tgt_mask\n\n# --- 3. DECODING STRATEGIES ---\n\ndef greedy_decode(model, src, max_len=50, bos_id=2, eos_id=3, device='cpu'):\n    \"\"\"Greedy decoding: selects the most likely token at each step.\"\"\"\n    src = src.to(device)\n    src_mask = (src != model.embedding.padding_idx).unsqueeze(1).unsqueeze(2).to(device) if model.embedding.padding_idx is not None else None\n\n    with torch.no_grad():\n        src_emb = model.dropout(model.pos_enc(model.embedding(src)))\n        enc_out = src_emb\n        for layer in model.encoder_layers:\n            enc_out = layer(enc_out, src_mask)\n        \n        ys = torch.ones(1, 1).fill_(bos_id).type(torch.long).to(device)\n        for _ in range(max_len - 1):\n            tgt_mask = (torch.triu(torch.ones(ys.size(1), ys.size(1)), diagonal=1) == 0).to(device)\n            out = model(src, ys, src_mask, tgt_mask)\n            prob = out[:, -1]\n            _, next_word = torch.max(prob, dim=1)\n            next_word = next_word.item()\n            ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n            if next_word == eos_id:\n                break\n    return ys\n\ndef beam_search_decode(model, src, max_len=50, beam_width=5, bos_id=2, eos_id=3, device='cpu'):\n    \"\"\"Beam search decoding: keeps track of k most likely sequences.\"\"\"\n    src = src.to(device)\n    src_mask = (src != model.embedding.padding_idx).unsqueeze(1).unsqueeze(2).to(device) if model.embedding.padding_idx is not None else None\n\n    with torch.no_grad():\n        src_emb = model.dropout(model.pos_enc(model.embedding(src)))\n        enc_out = src_emb\n        for layer in model.encoder_layers:\n            enc_out = layer(enc_out, src_mask)\n\n        # Start with <bos> token\n        sequences = [[torch.tensor([bos_id], device=device), 0.0]]\n\n        for _ in range(max_len):\n            all_candidates = []\n            for seq, score in sequences:\n                if seq[-1].item() == eos_id:\n                    all_candidates.append([seq, score])\n                    continue\n                \n                tgt_mask = (torch.triu(torch.ones(seq.size(0), seq.size(0)), diagonal=1) == 0).to(device)\n                out = model(src, seq.unsqueeze(0), src_mask, tgt_mask)\n                prob = torch.log_softmax(out[:, -1], dim=-1)\n                \n                topk_scores, topk_words = prob.topk(beam_width, dim=-1)\n\n                for i in range(beam_width):\n                    next_tok, next_score = topk_words[0][i], topk_scores[0][i]\n                    new_seq = torch.cat([seq, next_tok.unsqueeze(0)])\n                    new_score = score + next_score.item()\n                    all_candidates.append([new_seq, new_score])\n            \n            ordered = sorted(all_candidates, key=lambda tup: tup[1], reverse=True)\n            sequences = ordered[:beam_width]\n            \n            # Stop if all top sequences end with <eos>\n            if all(s[0][-1].item() == eos_id for s in sequences):\n                break\n\n    return sequences[0][0].unsqueeze(0)\n\n\n# --- 4. ATTENTION VISUALIZATION ---\n\ndef get_attention_weights(model, src, generated_seq, pad_id, device):\n    \"\"\"Performs a forward pass to capture attention weights.\"\"\"\n    model.eval()\n    with torch.no_grad():\n        src_mask, tgt_mask = create_masks(src, generated_seq, pad_id, device)\n        \n        src_emb = model.dropout(model.pos_enc(model.embedding(src)))\n        tgt_emb = model.dropout(model.pos_enc(model.embedding(generated_seq)))\n        \n        enc_out = src_emb\n        for layer in model.encoder_layers:\n            enc_out = layer(enc_out, src_mask)\n            \n        dec_out = tgt_emb\n        # We want the cross-attention from the LAST decoder layer\n        for i, layer in enumerate(model.decoder_layers):\n            dec_out = layer(dec_out, enc_out, src_mask, tgt_mask)\n        \n        # Access the stored weights from the last decoder's cross-attention module\n        attention = model.decoder_layers[-1].cross_mha.attention_weights\n        return attention\n\ndef plot_attention_heatmap(weights, src_tokens, tgt_tokens):\n    \"\"\"Plots and displays the attention heatmap.\"\"\"\n    fig, ax = plt.subplots(figsize=(10, 10))\n    # Squeeze to remove batch and head dimensions, then average over heads\n    weights = weights.squeeze(0).cpu().numpy()\n    if weights.ndim > 2:\n        weights = weights.mean(axis=0) # Average over heads\n\n    cax = ax.matshow(weights, cmap='bone')\n    fig.colorbar(cax)\n\n    ax.set_xticklabels([''] + src_tokens, rotation=90)\n    ax.set_yticklabels([''] + tgt_tokens)\n\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n\n    st.pyplot(fig)\n\n\n# --- 5. STREAMLIT UI ---\n\nst.set_page_config(layout=\"wide\")\nst.title(\"🤖 Empathetic Chatbot\")\nst.markdown(\"An interface to interact with a Transformer model trained on the Empathetic Dialogues dataset.\")\n\nmodel, tokenizer, device = load_model_and_tokenizer()\n\nif model is not None:\n    # Get available emotions from the tokenizer's special tokens\n    emotions = [\n        tok.replace(\"<emotion_\", \"\").replace(\">\", \"\") \n        for tok in tokenizer.get_vocab().keys() if tok.startswith(\"<emotion_\")\n    ]\n    emotions = sorted(list(set(emotions))) # Get unique sorted list\n\n    # Initialize session state for conversation history\n    if 'history' not in st.session_state:\n        st.session_state['history'] = []\n\n    # Sidebar for options\n    with st.sidebar:\n        st.header(\"Inference Options\")\n        selected_emotion = st.selectbox(\"Select an Emotion (optional)\", [\"none\"] + emotions)\n        decoding_strategy = st.radio(\"Decoding Strategy\", [\"Greedy Search\", \"Beam Search\"])\n        \n        beam_width = 5\n        if decoding_strategy == \"Beam Search\":\n            beam_width = st.slider(\"Beam Width\", min_value=2, max_value=10, value=5)\n        \n        show_attention = st.checkbox(\"Show Attention Heatmap\")\n\n    # Main chat interface\n    for message in st.session_state.history:\n        with st.chat_message(message[\"role\"]):\n            st.markdown(message[\"content\"])\n\n    # User input\n    if prompt := st.chat_input(\"How are you feeling today?\"):\n        # Add user message to history\n        st.session_state.history.append({\"role\": \"user\", \"content\": prompt})\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n\n        # Prepare model input\n        cleaned_prompt = normalize_text(prompt)\n        if selected_emotion != \"none\":\n            input_text = f\"Emotion: {selected_emotion} | Situation: {cleaned_prompt} Agent:\"\n        else:\n            input_text = f\"Situation: {cleaned_prompt} Agent:\"\n        \n        input_ids = tokenizer.encode(f\"<bos> {input_text}\").ids\n        src = torch.tensor([input_ids], device=device)\n\n        # Generate response based on selected strategy\n        with st.spinner(\"Thinking...\"):\n            if decoding_strategy == \"Greedy Search\":\n                output_ids = greedy_decode(model, src, bos_id=tokenizer.token_to_id(\"<bos>\"), eos_id=tokenizer.token_to_id(\"<eos>\"), device=device)\n            else: # Beam Search\n                output_ids = beam_search_decode(model, src, beam_width=beam_width, bos_id=tokenizer.token_to_id(\"<bos>\"), eos_id=tokenizer.token_to_id(\"<eos>\"), device=device)\n\n        # Decode and display response\n        response_text = tokenizer.decode(output_ids.squeeze(0).tolist(), skip_special_tokens=True).strip()\n        st.session_state.history.append({\"role\": \"assistant\", \"content\": response_text})\n        with st.chat_message(\"assistant\"):\n            st.markdown(response_text)\n\n            # Display attention heatmap if requested\n            if show_attention:\n                with st.expander(\"See Attention Weights\"):\n                    src_tokens = tokenizer.encode(f\"<bos> {input_text}\").tokens\n                    tgt_tokens = tokenizer.decode(output_ids.squeeze(0).tolist()).split()\n                    \n                    attention_weights = get_attention_weights(model, src, output_ids, tokenizer.token_to_id(\"<pad>\"), device)\n                    plot_attention_heatmap(attention_weights, src_tokens, tgt_tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T11:04:37.581462Z","iopub.execute_input":"2025-10-17T11:04:37.581794Z","iopub.status.idle":"2025-10-17T11:04:39.338684Z","shell.execute_reply.started":"2025-10-17T11:04:37.581769Z","shell.execute_reply":"2025-10-17T11:04:39.338131Z"}},"outputs":[{"name":"stderr","text":"2025-10-17 11:04:38.845 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:38.846 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:38.937 \n  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n  command:\n\n    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n2025-10-17 11:04:38.938 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:38.939 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:38.940 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:38.941 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:38.942 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:38.942 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:38.943 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:38.944 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:38.945 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.287 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.287 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.288 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.312 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.313 Session state does not function when running a script without `streamlit run`\n2025-10-17 11:04:39.313 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.315 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.316 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.316 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.317 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.318 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.318 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.319 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.320 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.320 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.321 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.321 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.322 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.323 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.323 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.324 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.324 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.325 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.326 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.326 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.327 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.327 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.328 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.331 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.331 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.332 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.332 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.333 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.334 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2025-10-17 11:04:39.334 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import gradio as gr\nimport torch\nfrom your_preprocessing_file import normalize_text  # Adjust import path\n\ndef beam_search_decode(model, src, beam_width=3, max_len=50):\n    model.eval()\n    src = src.to(device)\n    if len(src.shape) == 1:\n        src = src.unsqueeze(0)\n    batch_size = src.size(0)\n    src_mask = create_padding_mask(src, tokenizer.token_to_id(\"<pad>\")).to(device)\n    enc_out = model.dropout(model.pos_enc(model.embedding(src)))\n    for layer in model.encoder_layers:\n        enc_out = layer(enc_out, src_mask)\n    ys = torch.tensor([[tokenizer.token_to_id(\"<bos>\")]] * batch_size, device=device).repeat(beam_width, 1)\n    scores = torch.zeros(beam_width, device=device)\n    end_ids = [tokenizer.token_to_id(\"<eos>\")]\n    for _ in range(max_len):\n        tgt_mask = generate_square_subsequent_mask(ys.size(1)).to(device)\n        dec_out = model.dropout(model.pos_enc(model.embedding(ys)))\n        for layer in model.decoder_layers:\n            dec_out = layer(dec_out, enc_out, src_mask, tgt_mask)\n        pred = model.linear(dec_out[:, -1, :])\n        log_probs = torch.log_softmax(pred, dim=-1)\n        vocab_size = log_probs.size(-1)\n        log_probs = log_probs.view(beam_width, -1)\n        scores = scores.unsqueeze(-1) + log_probs\n        scores, indices = scores.view(-1).topk(beam_width, dim=0)\n        beam_ids = indices // vocab_size\n        token_ids = indices % vocab_size\n        ys = torch.cat((ys[beam_ids], token_ids.unsqueeze(-1)), dim=1)\n        if torch.all(torch.isin(ys[:, -1], end_ids)):\n            break\n    best_idx = scores.argmax()\n    return ys[best_idx].tolist()\n\ndef chat(emotion, situation, history, decode_strategy='greedy'):\n    input_text = f\"Emotion: {emotion} | Situation: {situation} Agent:\" if emotion else f\"Situation: {situation} Agent:\"\n    input_text = normalize_text(input_text)\n    input_ids = torch.tensor(tokenizer.encode(f\"<bos> {input_text}\").ids, dtype=torch.long)\n    if decode_strategy == 'greedy':\n        output_ids = greedy_decode(model, input_ids)\n    else:  # Beam search\n        output_ids = beam_search_decode(model, input_ids)\n    reply = tokenizer.decode(output_ids).strip()\n    history.append((situation, reply))\n    return history\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Empathetic Chatbot\")\n    emotion = gr.Textbox(label=\"Emotion (optional)\", value=\"\")\n    situation = gr.Textbox(label=\"Situation\")\n    chatbot = gr.Chatbot()\n    decode = gr.Radio([\"greedy\", \"beam\"], label=\"Decoding Strategy\", value=\"greedy\")\n    submit = gr.Button(\"Submit\")\n    submit.click(chat, [emotion, situation, chatbot, decode], [chatbot])\n    demo.launch(share=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T10:58:48.900418Z","iopub.execute_input":"2025-10-17T10:58:48.901164Z","iopub.status.idle":"2025-10-17T10:58:51.965725Z","shell.execute_reply.started":"2025-10-17T10:58:48.901132Z","shell.execute_reply":"2025-10-17T10:58:51.964659Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/1463582261.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myour_preprocessing_file\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize_text\u001b[0m  \u001b[0;31m# Adjust import path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbeam_search_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'your_preprocessing_file'"],"ename":"ModuleNotFoundError","evalue":"No module named 'your_preprocessing_file'","output_type":"error"}],"execution_count":13}]}